{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PetIdentifier.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1t_YQlcIC1YgsXwafyMTpbyc0kMSI0YJp",
      "authorship_tag": "ABX9TyObrJKuZC8dVaZjsG4r8ViG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophiehsu0213/Sciencefair2021DogBreedIdentify/blob/main/PetIdentifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6afjxJEjzN-N",
        "outputId": "55744239-207b-4161-fe68-b853923cc720"
      },
      "source": [
        "import IPython\n",
        "app = IPython.Application.instance()\n",
        "app.kernel.do_shutdown(True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'restart': True, 'status': 'ok'}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTUY40LT6Bqo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf843daa-b528-494c-8566-9ba8cd057291"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "base_model = keras.applications.VGG16(\n",
        "    weights='imagenet', \n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i45CT4tzg-k"
      },
      "source": [
        "base_model.trainable = False"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S2vclkwznsG"
      },
      "source": [
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "outputs = keras.layers.Dense(1)(x)\n",
        "model = keras.Model(inputs, outputs)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22lm6fWJznz0",
        "outputId": "40ca1bbd-6ef4-407a-d5ee-6cc204533d5b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,715,201\n",
            "Trainable params: 513\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWvMF7mRzn2K"
      },
      "source": [
        "model.compile(loss=keras.losses.BinaryCrossentropy(from_logits=True), metrics=[keras.metrics.BinaryAccuracy()])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtXjdq_-zn5w"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "        samplewise_center=True, \n",
        "        rotation_range=10,\n",
        "        zoom_range = 0.1,\n",
        "        width_shift_range=0.1,  \n",
        "        height_shift_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxtlaw59z0uN",
        "outputId": "b7aba101-c8d9-48c1-c24b-3f46e83df8ef"
      },
      "source": [
        "train_it = datagen.flow_from_directory('/content/drive/MyDrive/TeachableMachineDataSets/1/train', \n",
        "                                       target_size=(224, 224), \n",
        "                                       color_mode='rgb', \n",
        "                                       class_mode='binary', \n",
        "                                       batch_size=8)\n",
        "valid_it = datagen.flow_from_directory('/content/drive/MyDrive/TeachableMachineDataSets/1/valid', \n",
        "                                      target_size=(224, 224), \n",
        "                                      color_mode='rgb', \n",
        "                                      class_mode='binary', \n",
        "                                      batch_size=8)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 132 images belonging to 2 classes.\n",
            "Found 33 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OC7hL9_gVxia"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv5cpSeez0yk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c84ca8c-beed-462c-c6d9-f85fd23624a8"
      },
      "source": [
        "model.fit(train_it, steps_per_epoch=12, validation_data=valid_it, validation_steps=4, epochs=20)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "12/12 [==============================] - 40s 3s/step - loss: 1.3563 - binary_accuracy: 0.7609 - val_loss: 1.6318 - val_binary_accuracy: 0.7188\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 8s 727ms/step - loss: 0.8070 - binary_accuracy: 0.7717 - val_loss: 1.0845 - val_binary_accuracy: 0.6562\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 5s 411ms/step - loss: 0.5173 - binary_accuracy: 0.8696 - val_loss: 0.7407 - val_binary_accuracy: 0.7500\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 4s 354ms/step - loss: 0.4146 - binary_accuracy: 0.8646 - val_loss: 0.4527 - val_binary_accuracy: 0.8125\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 4s 330ms/step - loss: 0.2927 - binary_accuracy: 0.9130 - val_loss: 0.9503 - val_binary_accuracy: 0.6562\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 4s 323ms/step - loss: 0.2830 - binary_accuracy: 0.9022 - val_loss: 0.7605 - val_binary_accuracy: 0.7500\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 4s 332ms/step - loss: 0.2172 - binary_accuracy: 0.9457 - val_loss: 0.3792 - val_binary_accuracy: 0.8438\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 4s 330ms/step - loss: 0.1862 - binary_accuracy: 0.9457 - val_loss: 0.4257 - val_binary_accuracy: 0.8125\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 4s 333ms/step - loss: 0.1127 - binary_accuracy: 0.9674 - val_loss: 0.5493 - val_binary_accuracy: 0.8125\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 4s 338ms/step - loss: 0.0891 - binary_accuracy: 0.9688 - val_loss: 0.8249 - val_binary_accuracy: 0.7188\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 4s 330ms/step - loss: 0.0630 - binary_accuracy: 0.9783 - val_loss: 0.8618 - val_binary_accuracy: 0.7188\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 4s 333ms/step - loss: 0.0882 - binary_accuracy: 0.9674 - val_loss: 0.6766 - val_binary_accuracy: 0.8125\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 4s 331ms/step - loss: 0.0457 - binary_accuracy: 0.9783 - val_loss: 0.5337 - val_binary_accuracy: 0.7500\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 4s 330ms/step - loss: 0.0729 - binary_accuracy: 0.9783 - val_loss: 0.4147 - val_binary_accuracy: 0.7812\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 4s 331ms/step - loss: 0.0323 - binary_accuracy: 0.9891 - val_loss: 0.5867 - val_binary_accuracy: 0.7500\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 4s 328ms/step - loss: 0.0224 - binary_accuracy: 1.0000 - val_loss: 0.4934 - val_binary_accuracy: 0.8125\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 4s 326ms/step - loss: 0.0305 - binary_accuracy: 0.9891 - val_loss: 0.7234 - val_binary_accuracy: 0.7812\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 4s 328ms/step - loss: 0.0117 - binary_accuracy: 1.0000 - val_loss: 0.4482 - val_binary_accuracy: 0.7812\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 4s 330ms/step - loss: 0.0072 - binary_accuracy: 1.0000 - val_loss: 0.4129 - val_binary_accuracy: 0.8125\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 4s 326ms/step - loss: 0.0167 - binary_accuracy: 0.9891 - val_loss: 0.5832 - val_binary_accuracy: 0.7500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4f00021a50>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVhPvTzfz00v"
      },
      "source": [
        "base_model.trainable = True\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.RMSprop(learning_rate = .00001), \n",
        "              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=[keras.metrics.BinaryAccuracy()])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syp4ir5Sz04P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52eb2e5e-47f0-4d00-c04a-37dd6946db52"
      },
      "source": [
        "model.fit(train_it, steps_per_epoch=12, validation_data=valid_it, validation_steps=4, epochs=10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12/12 [==============================] - 11s 549ms/step - loss: 0.1013 - binary_accuracy: 0.9583 - val_loss: 0.4589 - val_binary_accuracy: 0.9062\n",
            "Epoch 2/10\n",
            "12/12 [==============================] - 7s 592ms/step - loss: 0.0761 - binary_accuracy: 0.9674 - val_loss: 0.9583 - val_binary_accuracy: 0.7500\n",
            "Epoch 3/10\n",
            "12/12 [==============================] - 6s 468ms/step - loss: 0.0019 - binary_accuracy: 1.0000 - val_loss: 0.6080 - val_binary_accuracy: 0.8750\n",
            "Epoch 4/10\n",
            "12/12 [==============================] - 6s 468ms/step - loss: 0.0082 - binary_accuracy: 1.0000 - val_loss: 2.0065 - val_binary_accuracy: 0.7188\n",
            "Epoch 5/10\n",
            "12/12 [==============================] - 6s 466ms/step - loss: 0.0013 - binary_accuracy: 1.0000 - val_loss: 0.7064 - val_binary_accuracy: 0.8750\n",
            "Epoch 6/10\n",
            "12/12 [==============================] - 6s 468ms/step - loss: 6.0534e-04 - binary_accuracy: 1.0000 - val_loss: 1.6550 - val_binary_accuracy: 0.7500\n",
            "Epoch 7/10\n",
            "12/12 [==============================] - 6s 466ms/step - loss: 0.0113 - binary_accuracy: 1.0000 - val_loss: 0.5580 - val_binary_accuracy: 0.8438\n",
            "Epoch 8/10\n",
            "12/12 [==============================] - 6s 466ms/step - loss: 0.0039 - binary_accuracy: 1.0000 - val_loss: 1.9857 - val_binary_accuracy: 0.7500\n",
            "Epoch 9/10\n",
            "12/12 [==============================] - 6s 474ms/step - loss: 0.0018 - binary_accuracy: 1.0000 - val_loss: 1.3187 - val_binary_accuracy: 0.7812\n",
            "Epoch 10/10\n",
            "12/12 [==============================] - 6s 470ms/step - loss: 3.2191e-04 - binary_accuracy: 1.0000 - val_loss: 1.0020 - val_binary_accuracy: 0.8438\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4e8b081b10>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV6IAigIz9-3"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from tensorflow.keras.preprocessing import image as image_utils\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "\n",
        "def show_image(image_path):\n",
        "    image = mpimg.imread(image_path)\n",
        "    plt.imshow(image)\n",
        "\n",
        "def make_predictions(image_path):\n",
        "    show_image(image_path)\n",
        "    image = image_utils.load_img(image_path, target_size=(224, 224))\n",
        "    image = image_utils.img_to_array(image)\n",
        "    image = image.reshape(1,224,224,3)\n",
        "    image = preprocess_input(image)\n",
        "    preds = model.predict(image)\n",
        "    return preds"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19QHIfaVz-yw"
      },
      "source": [
        "def IsThisTarget(image_path):\n",
        "    preds = make_predictions(image_path)\n",
        "    if preds[0] > 0:\n",
        "        print(\"Yes! Target Found.\")\n",
        "        print(preds[0])\n",
        "    else:\n",
        "        print(\"Not Target\")\n",
        "        print(preds[0])\n",
        "        "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYtZcQ5a1KMf"
      },
      "source": [
        "IsThisTarget('/content/drive/MyDrive/TeachableMachineDataSets/FinalTest/Target/891981.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXjLLvlCeQW5"
      },
      "source": [
        "IsThisTarget('/content/drive/MyDrive/TeachableMachineDataSets/FinalTest/Not Target/dog1.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJM_YUMGcK14"
      },
      "source": [
        "IsThisTarget('/content/drive/MyDrive/TeachableMachineDataSets/FinalTest/Target_1/n02085782_940.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}